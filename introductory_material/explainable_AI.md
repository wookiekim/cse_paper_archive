# Explainable AI (XAI)

How valuable are deep learning and AI predictions if we don't understand the reasoning behind them?
* AI algorithms need to have explanatory capabilities in order for users to understand why certain decisions were mdae.
* These explanatory capabilities: XAI

[AAAI 2020 Tutorial: Explainable AI](https://xaitutorial2020.github.io/)
[XAI papers](https://github.com/anguyen8/XAI-papers)

Deriving a general metric or standard to assess the quality of explainability in AI remains an open challenge to data.

A full-length textbook on this topic:
https://christophm.github.io/interpretable-ml-book/index.html

